{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.1.173:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.2.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=PySparkShell>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+----------+----------+----------+---------+----------+------+\n",
      "|      date|      open|      high|       low|     close|   volumn|  adjclose|result|\n",
      "+----------+----------+----------+----------+----------+---------+----------+------+\n",
      "|2016-12-30|166.440002|166.699997|     165.5|165.990005|2952800.0|164.687836|     0|\n",
      "|2016-12-29|166.020004|166.990005|     166.0|166.600006|1663500.0|165.293051|     1|\n",
      "|2016-12-28|167.289993|167.740005|     166.0|166.190002|1757500.0|164.886264|     0|\n",
      "|2016-12-27|166.979996|167.979996|166.850006|167.139999|1397500.0|165.828809|     1|\n",
      "|2016-12-23|     167.0|167.490005|166.449997|166.710007|1701200.0|165.402189|     0|\n",
      "|2016-12-22|167.360001|168.229996|166.580002|167.059998|2802600.0|165.749434|     0|\n",
      "|2016-12-21|    166.25|167.940002|    165.25|167.330002|3575700.0|166.017321|     1|\n",
      "|2016-12-20|167.490005|    168.25|166.449997|167.600006|2174600.0|166.285207|     1|\n",
      "|2016-12-19|166.830002|167.259995|     166.0|166.679993|2955900.0|165.372411|     0|\n",
      "|2016-12-16|168.970001|169.110001|166.059998|166.729996|7120600.0|165.422021|     0|\n",
      "|2016-12-15|168.009995|169.850006|167.779999|168.020004|3388600.0| 166.70191|     1|\n",
      "|2016-12-14|168.369995|169.889999|167.449997|168.509995|4124200.0|167.188056|     1|\n",
      "|2016-12-13|165.679993|169.949997|165.679993|168.289993|5932300.0|166.969781|     1|\n",
      "|2016-12-12|166.720001|166.789993|165.070007|     165.5|3392300.0|164.201675|     0|\n",
      "|2016-12-09|165.179993|166.720001|164.600006|166.520004|3146900.0|165.213677|     1|\n",
      "|2016-12-08|164.869995|     166.0|164.220001|165.360001|3266400.0|164.062774|     1|\n",
      "|2016-12-07|160.600006|165.179993|160.389999|164.789993|4435100.0|163.497238|     1|\n",
      "|2016-12-06|160.130005|160.789993|158.929993|160.350006|2859000.0|159.092082|     1|\n",
      "|2016-12-05|160.850006|161.149994|159.589996|159.839996|3447100.0|158.586073|     0|\n",
      "|2016-12-02|     159.0|160.289993|158.410004|160.020004|2740900.0|158.764669|     1|\n",
      "+----------+----------+----------+----------+----------+---------+----------+------+\n",
      "only showing top 20 rows\n",
      "\n",
      "root\n",
      " |-- date: date (nullable = true)\n",
      " |-- open: double (nullable = true)\n",
      " |-- high: double (nullable = true)\n",
      " |-- low: double (nullable = true)\n",
      " |-- close: double (nullable = true)\n",
      " |-- volumn: double (nullable = true)\n",
      " |-- adjclose: double (nullable = true)\n",
      " |-- result: integer (nullable = true)\n",
      " |-- indexedLabel: double (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      " |-- rawPrediction: vector (nullable = true)\n",
      " |-- probability: vector (nullable = true)\n",
      " |-- prediction: double (nullable = true)\n",
      "\n",
      "+------------+----------+--------------------+--------------------+\n",
      "|indexedLabel|prediction|            features|         probability|\n",
      "+------------+----------+--------------------+--------------------+\n",
      "|         1.0|       0.0|[133.649994,133.7...|[0.68478260869565...|\n",
      "|         1.0|       0.0|[130.110001,132.1...|[0.68478260869565...|\n",
      "|         1.0|       0.0|[125.0,125.290001...|[0.68478260869565...|\n",
      "|         1.0|       0.0|[118.779999,119.6...|[0.68478260869565...|\n",
      "|         1.0|       0.0|[133.139999,133.4...|[0.68478260869565...|\n",
      "|         1.0|       0.0|[134.509995,134.9...|[0.68478260869565...|\n",
      "|         1.0|       0.0|[132.0,133.360001...|[0.68478260869565...|\n",
      "|         1.0|       0.0|[141.240005,141.4...|[0.68478260869565...|\n",
      "|         1.0|       0.0|[148.0,148.029999...|[0.68478260869565...|\n",
      "|         1.0|       0.0|[149.949997,150.4...|[0.68478260869565...|\n",
      "|         1.0|       0.0|[151.5,152.759995...|[0.68478260869565...|\n",
      "|         1.0|       0.0|[149.440002,151.0...|[0.68478260869565...|\n",
      "|         1.0|       0.0|[146.490005,147.3...|[0.68478260869565...|\n",
      "|         1.0|       0.0|[149.210007,149.3...|[0.68478260869565...|\n",
      "|         1.0|       0.0|[149.210007,149.5...|[0.68478260869565...|\n",
      "|         1.0|       0.0|[147.990005,148.5...|[0.68478260869565...|\n",
      "|         1.0|       0.0|[146.479996,146.9...|[0.68478260869565...|\n",
      "|         1.0|       0.0|[147.610001,147.9...|[0.68478260869565...|\n",
      "|         1.0|       0.0|[152.789993,153.3...|[0.68478260869565...|\n",
      "|         1.0|       0.0|[151.630005,152.5...|[0.68478260869565...|\n",
      "+------------+----------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "準確率=0.580 (37\t88)\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import os\n",
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler, VectorIndexer\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "class Utils():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    # 敘述性統計：平均數 標準差\n",
    "    def getStatValue(self, df, fieldName):\n",
    "        stat = df.select(avg(fieldName), stddev(fieldName)).collect()\n",
    "        return stat[0]\n",
    "\n",
    "class LoadSavedData(Utils):\n",
    "    # 繼承\n",
    "    def __init__(self):\n",
    "        Utils.__init__(self)\n",
    "\n",
    "    # 載入資料集檔案\n",
    "    def loadData(self, dataFile):\n",
    "        sql = 'SELECT * FROM parquet.`%s`' % dataFile\n",
    "        df = sqlContext.sql(sql)\n",
    "        return df\n",
    "\n",
    "    # 列印敘述性統計\n",
    "    def printStats(self, df, fields=None):\n",
    "        if fields is None:\n",
    "            df.describe().show()\n",
    "        else:\n",
    "            for field in fields:\n",
    "                df.describe(field).show()\n",
    "\n",
    "    # 決策樹\n",
    "    def DT(self, trainingData, testData, labelIndexer, features):\n",
    "        # 組合自變數欄位群，並指明衍生欄位名稱\n",
    "        '''\n",
    "            例如 m1=2 m2=3 n1= 4 n2=5\n",
    "            features會把它組合成\n",
    "            ['2','3','4','5']\n",
    "        '''\n",
    "        features = (VectorAssembler()\n",
    "                        .setInputCols(features)\n",
    "                        .setOutputCol('features'))\n",
    "\n",
    "        # 取得決策樹介面\n",
    "        dt = DecisionTreeClassifier(labelCol='indexedLabel', featuresCol='features')\n",
    "\n",
    "        # 進行決策樹分析\n",
    "        pipeline = Pipeline(stages=[labelIndexer, features, dt])\n",
    "\n",
    "        # 產生決策樹分析模型\n",
    "        model = pipeline.fit(trainingData)\n",
    "\n",
    "        # 推測值\n",
    "        predictions = model.transform(testData)\n",
    "\n",
    "        return predictions\n",
    "\n",
    "    # 列印決策樹分析結果\n",
    "    def printStatsDT(self, predictions):\n",
    "        # 篩選分析結果欄位群\n",
    "        # indexedLabel 算出來的值\n",
    "        # prediction 演算法預測的值\n",
    "        # features [開盤,尾盤]\n",
    "        result = predictions.select('indexedLabel', 'prediction', 'features', 'probability')\n",
    "\n",
    "        # 篩選預測錯誤資料\n",
    "        resultError = result.where(result.indexedLabel != result.prediction)\n",
    "        resultError.show()\n",
    "\n",
    "        print(u'準確率=%.3f (%d\\t%d)' % (1.000 - resultError.count() / result.count(),\n",
    "                resultError.count(),\n",
    "                result.count()))\n",
    "\n",
    "def m_fun(o,c):\n",
    "    if o>c:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "# 主程式\n",
    "def main(dataDir):\n",
    "    # 類別初始化\n",
    "    worker = LoadSavedData()\n",
    "\n",
    "    # 載入資料集\n",
    "    df = worker.loadData(dataFile='%s/IBM.parquet' % dataDir)\n",
    "     \n",
    "    my_m = udf(m_fun, IntegerType())\n",
    "    df = df.withColumn('result', my_m('open', 'close'))\n",
    "    \n",
    "    df.show()\n",
    "    # 資料隨機抽樣成二群\n",
    "    # 將資料分成2群，一群為trainingData,另一個為testData,經過測試 7:3比例ok\n",
    "    (trainingData, testData) = df.randomSplit([0.7, 0.3])\n",
    "\n",
    "    # 為類別值建立數值對照表\n",
    "    # 建立對照表, 輸入的欄位為shape，輸出的為indexedLabel\n",
    "   \n",
    "    labelIndexer = StringIndexer(inputCol='result', outputCol='indexedLabel').fit(df)\n",
    "    \n",
    "    # 決策樹：指定自變數欄位群\n",
    "    # 載入worker.DT\n",
    "    result = worker.DT(trainingData, testData, labelIndexer, df.columns[1:5])\n",
    "    result.printSchema()\n",
    "\n",
    "    # 列印決策樹分析結果\n",
    "    worker.printStatsDT(result)\n",
    "\n",
    "# 程式進入點\n",
    "if __name__ == '__main__':\n",
    "    global sc, sqlContext\n",
    "\n",
    "    # 本地資源運算\n",
    "    appName = 'Cup-11'\n",
    "    master = 'local'\n",
    "\n",
    "    #sc = SparkContext(conf=SparkConf().setAppName(appName).setMaster(master))\n",
    "\n",
    "    # 取得資料庫介面\n",
    "    sqlContext = SQLContext(sc)\n",
    "\n",
    "    # 調用主程式\n",
    "    homeDir = os.environ['HOME']\n",
    "    dirName = 'Data'\n",
    "    sampleDir = '%s/Sample' % homeDir\n",
    "    dataDir = '%s/Data' % homeDir\n",
    "\n",
    "    main(dataDir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
