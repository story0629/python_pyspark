{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.1.173:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.2.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=PySparkShell>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iris-virginica\n",
      "Iris-setosa\n",
      "Iris-versicolor\n",
      "Row(m1=7.7, m2=2.6, n1=6.9, n2=2.3, shape='Iris-virginica', label=2, mn1=53.130001068115234, mn2=1.1304347515106201)\n",
      "+---+---+---+---+-----------+-----+----+---------+\n",
      "| m1| m2| n1| n2|      shape|label| mn1|      mn2|\n",
      "+---+---+---+---+-----------+-----+----+---------+\n",
      "|5.1|3.5|1.4|0.2|Iris-setosa|    0|7.14|     17.5|\n",
      "|4.9|3.0|1.4|0.2|Iris-setosa|    0|6.86|     15.0|\n",
      "|4.7|3.2|1.3|0.2|Iris-setosa|    0|6.11|     16.0|\n",
      "|4.6|3.1|1.5|0.2|Iris-setosa|    0| 6.9|     15.5|\n",
      "|5.0|3.6|1.4|0.2|Iris-setosa|    0| 7.0|     18.0|\n",
      "|5.4|3.9|1.7|0.4|Iris-setosa|    0|9.18|     9.75|\n",
      "|4.6|3.4|1.4|0.3|Iris-setosa|    0|6.44|11.333333|\n",
      "|5.0|3.4|1.5|0.2|Iris-setosa|    0| 7.5|     17.0|\n",
      "|4.4|2.9|1.4|0.2|Iris-setosa|    0|6.16|     14.5|\n",
      "|4.9|3.1|1.5|0.1|Iris-setosa|    0|7.35|     31.0|\n",
      "|5.4|3.7|1.5|0.2|Iris-setosa|    0| 8.1|     18.5|\n",
      "|4.8|3.4|1.6|0.2|Iris-setosa|    0|7.68|     17.0|\n",
      "|4.8|3.0|1.4|0.1|Iris-setosa|    0|6.72|     30.0|\n",
      "|4.3|3.0|1.1|0.1|Iris-setosa|    0|4.73|     30.0|\n",
      "|5.8|4.0|1.2|0.2|Iris-setosa|    0|6.96|     20.0|\n",
      "|5.7|4.4|1.5|0.4|Iris-setosa|    0|8.55|     11.0|\n",
      "|5.4|3.9|1.3|0.4|Iris-setosa|    0|7.02|     9.75|\n",
      "|5.1|3.5|1.4|0.3|Iris-setosa|    0|7.14|11.666667|\n",
      "|5.7|3.8|1.7|0.3|Iris-setosa|    0|9.69|12.666667|\n",
      "|5.1|3.8|1.5|0.3|Iris-setosa|    0|7.65|12.666667|\n",
      "+---+---+---+---+-----------+-----+----+---------+\n",
      "only showing top 20 rows\n",
      "\n",
      "1\n",
      "2\n",
      "0\n",
      "      m2\t3.054\t0.434\n",
      "      n1\t3.759\t1.764\n",
      "      n2\t1.199\t0.763\n",
      "+-------+-------------------+\n",
      "|summary|                 m2|\n",
      "+-------+-------------------+\n",
      "|  count|                150|\n",
      "|   mean| 3.0540000000000007|\n",
      "| stddev|0.43359431136217375|\n",
      "|    min|                2.0|\n",
      "|    max|                4.4|\n",
      "+-------+-------------------+\n",
      "\n",
      "+-------+------------------+\n",
      "|summary|                n1|\n",
      "+-------+------------------+\n",
      "|  count|               150|\n",
      "|   mean|3.7586666666666693|\n",
      "| stddev| 1.764420419952262|\n",
      "|    min|               1.0|\n",
      "|    max|               6.9|\n",
      "+-------+------------------+\n",
      "\n",
      "+-------+------------------+\n",
      "|summary|                n2|\n",
      "+-------+------------------+\n",
      "|  count|               150|\n",
      "|   mean|1.1986666666666672|\n",
      "| stddev|0.7631607417008414|\n",
      "|    min|               0.1|\n",
      "|    max|               2.5|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import os\n",
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "import numpy\n",
    "\n",
    "class Utils():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    # 敘述性統計：平均數 標準差\n",
    "    def getStatValue(self, df, fieldName):\n",
    "        stat = df.select(avg(fieldName), stddev(fieldName)).collect()\n",
    "        return stat[0]\n",
    "\n",
    "class LoadSavedData(Utils):\n",
    "    # 繼承\n",
    "    def __init__(self):\n",
    "        Utils.__init__(self)\n",
    "        # 執行和Utils的__init__一樣的動作\n",
    "        \n",
    "    # 載入資料集檔案\n",
    "    def loadData(self, dataFile):\n",
    "        sql = 'SELECT * FROM parquet.`%s`' % dataFile\n",
    "        # SELECT * FROM parquet.datafile\n",
    "        df = sqlContext.sql(sql)\n",
    "        return df\n",
    "\n",
    "    # 列印敘述性統計\n",
    "    def printStats(self, df, fields=None):\n",
    "        if fields is None:\n",
    "            df.describe().show()\n",
    "        else:\n",
    "            for field in fields:\n",
    "                df.describe(field).show()\n",
    "\n",
    "# 對照轉換欄位相應值函數\n",
    "def changeValue(shape):\n",
    "    idShape = 0\n",
    "    if shape == 'Iris-versicolor':\n",
    "        idShape = 1\n",
    "    elif shape == 'Iris-virginica':\n",
    "        idShape = 2\n",
    "\n",
    "    return idShape\n",
    "    # 將傳過來的shape 回傳idShape\n",
    "\n",
    "def mn1(m1,n1):\n",
    "    return m1*n1\n",
    "def mn2(m2,n2):\n",
    "    return m2/n2\n",
    "\n",
    "# 主程式\n",
    "def main(dataDir):\n",
    "    # 資料欄位名稱\n",
    "    fields = ['m1', 'm2', 'n1', 'n2', 'shape']\n",
    "\n",
    "    # 類別初始化\n",
    "    worker = LoadSavedData()\n",
    "\n",
    "    # 載入資料集\n",
    "    df = worker.loadData(dataFile='%s/iris.parquet' % dataDir)\n",
    "\n",
    "    # 萃取欄位不重複值\n",
    "    shapes = df.select(fields[4]).distinct().collect()\n",
    "    for shape in shapes:\n",
    "        print(shape[0])\n",
    "        # distinct 為去除重複 去除field[4]->shape的重複\n",
    "\n",
    "    # 自訂函數：對照轉換欄位相應值\n",
    "    myUdf = udf(changeValue, IntegerType())\n",
    "    # myUdf 的變數為自訂\n",
    "    # udf 為DataFrame的自訂函式\n",
    "    # 第一個值為要用的函式 第二個值為函式抓出來值的資料格\n",
    "    \n",
    "    mymn1 = udf(mn1, FloatType())\n",
    "    mymn2 = udf(mn2, FloatType())\n",
    "\n",
    "    # 對照轉換欄位相應值，衍生新欄位，取代原資料集\n",
    "    df = df.withColumn('label', myUdf('shape')) \\\n",
    "           .withColumn('mn1',mymn1(\"m1\",\"n1\")) \\\n",
    "           .withColumn(\"mn2\",mymn2(\"m2\",\"n2\"))\n",
    "    # withColumn為dataframe 新增欄位的語法\n",
    "    # 第一個為心欄位的名稱 第二個為心欄位的值\n",
    "    \n",
    "    #df = df.where(\"mn1>3 and mn2 >20\")\n",
    "    #df = df.where(col(\"mn1\")>3).where(col(\"mn2\")>20)\n",
    "    # 使用where將要篩選的值當成字串\n",
    "    \n",
    "    mmnn1 = numpy.array(df.select('mn1').collect())\n",
    "    mmnn1_mean = mmnn1.mean()\n",
    "    \n",
    "    data1 = df.where(col(\"mn1\")>mmnn1_mean) \\\n",
    "           .sort(desc(\"mn1\")) \\\n",
    "           .limit(3) \\\n",
    "           .collect()\n",
    "        \n",
    "    data2 = df.where(col(\"mn1\")>mmnn1_mean) \\\n",
    "           .limit(3) \\\n",
    "           .collect()\n",
    "    print(data1)\n",
    "    #print(data2)\n",
    "    \n",
    "    df.show()\n",
    "\n",
    "    # 萃取衍生欄位不重複值\n",
    "    idShapes = df.select('label').distinct().collect()\n",
    "    for idShape in idShapes:\n",
    "        print(idShape[0])\n",
    "    # 已經新增欄位了,心欄位的label一樣可以使用distinct 去除重複\n",
    "\n",
    "    # 列印敘述性統計：平均數 標準差\n",
    "    for field in fields[1:4]:\n",
    "        stat = worker.getStatValue(df, field)\n",
    "        print('%8s\\t%.3f\\t%.3f' % (field, stat[0], stat[1]))\n",
    "\n",
    "    # 列印敘述性統計\n",
    "    worker.printStats(df, fields[1:4])\n",
    "\n",
    "    # 保存資料集至指定目錄下\n",
    "    df.write.mode('overwrite').save('%s/iris2.parquet' % dataDir,\n",
    "                                        format='parquet')\n",
    "\n",
    "\n",
    "# 程式進入點\n",
    "if __name__ == '__main__':\n",
    "    global sc, sqlContext\n",
    "\n",
    "    # 本地資源運算\n",
    "    appName = 'Cup-01'\n",
    "    master = 'local'\n",
    "\n",
    "    #sc = SparkContext(conf=SparkConf().setAppName(appName).setMaster(master))\n",
    "    # 如果不市使用jupyter就需要 jupyter會預先設定好\n",
    "\n",
    "    # 取得資料庫介面\n",
    "    sqlContext = SQLContext(sc)\n",
    "\n",
    "    # 調用主程式\n",
    "    homeDir = os.environ['HOME']\n",
    "    dirName = 'Data'\n",
    "    sampleDir = '%s/Sample' % homeDir\n",
    "    dataDir = '%s/Data' % homeDir\n",
    "\n",
    "    main(dataDir)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
